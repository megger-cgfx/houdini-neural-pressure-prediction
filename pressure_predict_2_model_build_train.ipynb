{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c4988d-3377-4379-9c74-75425a5b9876",
   "metadata": {},
   "source": [
    "# Generator\n",
    "Build generator architecture with:\n",
    "* Attention blocks\n",
    "* Spectral Convolutions\n",
    "* Upsampling and Downsampling layers\n",
    "* Resnet blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0633912-c37d-4ebc-bac0-8e1f23ed119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def attention_block(x, filters):\n",
    "    \"\"\"Self-attention mechanism with dynamic input support\"\"\"\n",
    "    shape = tf.shape(x)\n",
    "    batch_size, height, width = shape[0], shape[1], shape[2]\n",
    "    \n",
    "    f = tf.keras.layers.Conv2D(filters // 8, 1)(x)\n",
    "    g = tf.keras.layers.Conv2D(filters // 8, 1)(x)\n",
    "    h = tf.keras.layers.Conv2D(filters, 1)(x)\n",
    "    \n",
    "    f = tf.reshape(f, [batch_size, -1, filters // 8])\n",
    "    g = tf.reshape(g, [batch_size, -1, filters // 8])\n",
    "    h = tf.reshape(h, [batch_size, -1, filters])\n",
    "    \n",
    "    s = tf.matmul(f, g, transpose_b=True)\n",
    "    beta = tf.nn.softmax(s)\n",
    "    \n",
    "    o = tf.matmul(beta, h)\n",
    "    o = tf.reshape(o, [batch_size, height, width, filters])\n",
    "    \n",
    "    gamma = tf.Variable(0.0, trainable=True)\n",
    "    return x + gamma * o\n",
    "\n",
    "def spectral_conv2d(filters, kernel_size, strides=1):\n",
    "    return tf.keras.layers.Conv2D(\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        strides=strides,\n",
    "        padding='same',\n",
    "        kernel_initializer='orthogonal',\n",
    "        use_bias=False\n",
    "    )\n",
    "\n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(spectral_conv2d(filters, size, strides=2))\n",
    "    \n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization(momentum=0.9))\n",
    "    \n",
    "    result.add(tf.keras.layers.PReLU(shared_axes=[1, 2]))\n",
    "    return result\n",
    "\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2DTranspose(\n",
    "            filters, size, strides=2,\n",
    "            padding='same',\n",
    "            kernel_initializer='orthogonal',\n",
    "            use_bias=False\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    result.add(tf.keras.layers.LayerNormalization())\n",
    "    \n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.SpatialDropout2D(0.5))\n",
    "    \n",
    "    result.add(tf.keras.layers.PReLU(shared_axes=[1, 2]))\n",
    "    return result\n",
    "\n",
    "def resnet_block(input_tensor, filters, kernel_size=3):\n",
    "    def squeeze_excite_block(input_tensor, ratio=16):\n",
    "        channels = input_tensor.shape[-1]\n",
    "        \n",
    "        se = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
    "        se = tf.keras.layers.Reshape((1, 1, channels))(se)\n",
    "        se = tf.keras.layers.Dense(channels // ratio, activation='relu')(se)\n",
    "        se = tf.keras.layers.Dense(channels, activation='sigmoid')(se)\n",
    "        \n",
    "        return tf.keras.layers.Multiply()([input_tensor, se])\n",
    "    \n",
    "    x = spectral_conv2d(filters, kernel_size)(input_tensor)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    \n",
    "    x = spectral_conv2d(filters, kernel_size)(x)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    \n",
    "    x = squeeze_excite_block(x)\n",
    "    x = tf.keras.layers.Add()([x, input_tensor])\n",
    "    x = tf.keras.layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d137debf-2329-4beb-9fc8-22c32c683d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class DynamicPaddingLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"Custom layer to handle padding to multiples of n\"\"\"\n",
    "    def __init__(self, target_multiple=8, **kwargs):\n",
    "        super(DynamicPaddingLayer, self).__init__(**kwargs)\n",
    "        self.target_multiple = target_multiple\n",
    "        self.built = False\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Create the variables in build method\n",
    "        self.pad_top = self.add_weight(\n",
    "            name='pad_top',\n",
    "            shape=(),\n",
    "            dtype=tf.int32,\n",
    "            trainable=False,\n",
    "            initializer=tf.keras.initializers.Constant(0)\n",
    "        )\n",
    "        self.pad_bottom = self.add_weight(\n",
    "            name='pad_bottom',\n",
    "            shape=(),\n",
    "            dtype=tf.int32,\n",
    "            trainable=False,\n",
    "            initializer=tf.keras.initializers.Constant(0)\n",
    "        )\n",
    "        self.pad_left = self.add_weight(\n",
    "            name='pad_left',\n",
    "            shape=(),\n",
    "            dtype=tf.int32,\n",
    "            trainable=False,\n",
    "            initializer=tf.keras.initializers.Constant(0)\n",
    "        )\n",
    "        self.pad_right = self.add_weight(\n",
    "            name='pad_right',\n",
    "            shape=(),\n",
    "            dtype=tf.int32,\n",
    "            trainable=False,\n",
    "            initializer=tf.keras.initializers.Constant(0)\n",
    "        )\n",
    "        self.built = True\n",
    "        super(DynamicPaddingLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        shape = tf.shape(inputs)\n",
    "        height, width = shape[1], shape[2]\n",
    "        \n",
    "        # Calculate required padding\n",
    "        pad_height = (self.target_multiple - (height % self.target_multiple)) % self.target_multiple\n",
    "        pad_width = (self.target_multiple - (width % self.target_multiple)) % self.target_multiple\n",
    "        \n",
    "        # Calculate padding for each dimension\n",
    "        pad_top = pad_height // 2\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        pad_left = pad_width // 2\n",
    "        pad_right = pad_width - pad_left\n",
    "        \n",
    "        # Update the padding variables\n",
    "        self.pad_top.assign(pad_top)\n",
    "        self.pad_bottom.assign(pad_bottom)\n",
    "        self.pad_left.assign(pad_left)\n",
    "        self.pad_right.assign(pad_right)\n",
    "        \n",
    "        # Pad the tensor\n",
    "        paddings = [[0, 0], [pad_top, pad_bottom], [pad_left, pad_right], [0, 0]]\n",
    "        padded_tensor = tf.pad(inputs, paddings, mode='REFLECT')\n",
    "        \n",
    "        return padded_tensor\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(DynamicPaddingLayer, self).get_config()\n",
    "        config.update({\n",
    "            'target_multiple': self.target_multiple\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class UnpadLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"Custom layer to remove padding\"\"\"\n",
    "    def __init__(self, padding_layer, **kwargs):\n",
    "        super(UnpadLayer, self).__init__(**kwargs)\n",
    "        self.padding_layer = padding_layer\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        shape = tf.shape(inputs)\n",
    "        height = shape[1] - (self.padding_layer.pad_top + self.padding_layer.pad_bottom)\n",
    "        width = shape[2] - (self.padding_layer.pad_left + self.padding_layer.pad_right)\n",
    "        \n",
    "        return inputs[:, \n",
    "                     self.padding_layer.pad_top:self.padding_layer.pad_top + height,\n",
    "                     self.padding_layer.pad_left:self.padding_layer.pad_left + width,\n",
    "                     :]\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(UnpadLayer, self).get_config()\n",
    "        config.update({\n",
    "            'padding_layer': self.padding_layer\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "def build_generator(input_shape=(None, None, 3)):\n",
    "    \"\"\"Build generator with support for arbitrary input sizes\"\"\"\n",
    "    tf.keras.backend.set_floatx('float32')\n",
    "    \n",
    "    # Input layer\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Add padding layer\n",
    "    padding_layer = DynamicPaddingLayer(target_multiple=8)\n",
    "    x = padding_layer(inputs)\n",
    "    \n",
    "    # Initial convolution\n",
    "    x = spectral_conv2d(32, 7)(x)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    \n",
    "    # Downsampling path\n",
    "    down_stack = [\n",
    "        downsample(64, 3, apply_batchnorm=False),\n",
    "        downsample(128, 3),\n",
    "        downsample(256, 3),\n",
    "    ]\n",
    "    \n",
    "    # Store skip connections\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "    \n",
    "    # ResNet blocks\n",
    "    num_res_blocks = 9\n",
    "    for i in range(num_res_blocks):\n",
    "        x = resnet_block(x, filters=256)\n",
    "        if i % 2 == 0:\n",
    "            x = attention_block(x, filters=256)\n",
    "    \n",
    "    # Upsampling path\n",
    "    up_stack = [\n",
    "        upsample(128, 3, apply_dropout=True),\n",
    "        upsample(64, 3),\n",
    "        upsample(32, 3),\n",
    "    ]\n",
    "    \n",
    "    # Decoder with skip connections\n",
    "    skips = reversed(skips[:-1])\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = attention_block(x, x.shape[-1])\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "    \n",
    "    # Final output layer\n",
    "    x = tf.keras.layers.Conv2DTranspose(\n",
    "        3, 4,\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        kernel_initializer='orthogonal',\n",
    "        activation='tanh'\n",
    "    )(x)\n",
    "    \n",
    "    # Remove padding using custom unpad layer\n",
    "    outputs = UnpadLayer(padding_layer)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a8b41e-39bb-4a7d-b7b7-beb0f7047c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Test function\n",
    "def test_arbitrary_generator_input():\n",
    "    model = build_generator(input_shape=(None, None, 3))\n",
    "    \n",
    "    test_sizes = [\n",
    "        (1, 65, 65, 3),    # Odd dimensions\n",
    "        (1, 100, 100, 3),  # Non-multiple of 8\n",
    "        (1, 128, 128, 3),  # Multiple of 8\n",
    "        (1, 77, 153, 3),   # Different height and width\n",
    "    ]\n",
    "    \n",
    "    for size in test_sizes:\n",
    "        test_input = tf.random.normal(size)\n",
    "        output = model(test_input)\n",
    "        input_hw = size[1:3]\n",
    "        output_hw = tuple(output.shape[1:3])\n",
    "        print(f\"Input size: {input_hw}\")\n",
    "        print(f\"Output size: {output_hw}\")\n",
    "        print(f\"Shapes match: {input_hw == output_hw}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_arbitrary_generator_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a6353b-9981-430e-ac98-0fc777362bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator = build_generator(input_shape=(None, None, 3))\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae5af20-319f-43c3-889d-508c1f4f81eb",
   "metadata": {},
   "source": [
    "# Discriminator\n",
    "Build discriminator architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad68043-ce9d-4fd8-8242-abe0b6fe99e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCRIMINATOR\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_discriminator(input_shape=(None, None, 3)):\n",
    "    \"\"\"\n",
    "    Stabilized PatchGAN discriminator that handles arbitrary input sizes\n",
    "    \"\"\"\n",
    "    # Add spectral normalization\n",
    "    def conv_block(x, filters, kernel_size=4, strides=2, apply_norm=True):\n",
    "        x = tfa.layers.SpectralNormalization(\n",
    "            layers.Conv2D(filters, kernel_size, strides, padding='same',\n",
    "                         kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "                         use_bias=False))(x)\n",
    "        \n",
    "        if apply_norm:\n",
    "            x = tfa.layers.InstanceNormalization()(x)\n",
    "        \n",
    "        x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "        return x\n",
    "\n",
    "    # Use None for dynamic dimensions\n",
    "    inp = layers.Input(shape=input_shape, dtype=tf.float32, name='input_image')\n",
    "    tar = layers.Input(shape=input_shape, dtype=tf.float32, name='target_image')\n",
    "    \n",
    "    # Add noise directly to inputs\n",
    "    noise_scale = tf.Variable(0.005, trainable=True)\n",
    "    noise = tf.random.normal(tf.shape(inp)) * noise_scale\n",
    "    x = layers.Concatenate(axis=-1)([inp + noise, tar + noise])\n",
    "    \n",
    "    # Network will now work with any input size\n",
    "    x = conv_block(x, 32, strides=2)        # H/2 x W/2\n",
    "    x = conv_block(x, 64, strides=2)        # H/4 x W/4\n",
    "    x = conv_block(x, 128, strides=2)       # H/8 x W/8\n",
    "    x = conv_block(x, 256, strides=1)       # H/8 x W/8\n",
    "    \n",
    "    x = layers.Conv2D(1, 3, strides=1, padding='same',\n",
    "                     kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc695f2-18c0-422f-a0d6-4516dcfccbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81678b1-c485-44c9-8c0f-6b97e0b71864",
   "metadata": {},
   "source": [
    "# Loss function class\n",
    "An object with physics-informed loss for the generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c831ece8-dd32-41be-9d1b-8d374e4ded29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class FluidGANLoss:\n",
    "    def __init__(self, discriminator, lambda_gp=10.0, lambda_physics=1.0):\n",
    "        self.discriminator = discriminator\n",
    "        self.lambda_gp = lambda_gp\n",
    "        self.lambda_physics = lambda_physics\n",
    "        # Add adaptive weights\n",
    "        self.adversarial_weight = tf.Variable(1.0, trainable=False)\n",
    "        self.running_gen_loss = tf.Variable(0.0, trainable=False)\n",
    "        self.running_disc_loss = tf.Variable(0.0, trainable=False)\n",
    "        self.beta = 0.99  # For running average\n",
    "        \n",
    "    def generator_loss(self, disc_generated_output, y_true, y_pred):\n",
    "        # Use least squares GAN loss instead of relativistic\n",
    "        # This tends to be more stable for fluid dynamics\n",
    "        adversarial_loss = tf.reduce_mean(tf.square(disc_generated_output - 1.0))\n",
    "        \n",
    "        # Enhanced L1 loss with focus on high-gradient regions\n",
    "        base_l1 = tf.abs(y_true - y_pred)\n",
    "        grad_weights = tf.reduce_mean(tf.image.sobel_edges(y_true), axis=-1)\n",
    "        grad_weights = tf.nn.softmax(grad_weights * 10.0)  # Temperature scaling\n",
    "        weighted_l1 = base_l1 * (1.0 + grad_weights)\n",
    "        l1_loss = tf.reduce_mean(weighted_l1)\n",
    "        \n",
    "        # Gradient matching with different scales\n",
    "        grad_loss = 0.0\n",
    "        scales = [1, 2]\n",
    "        for scale in scales:\n",
    "            if scale > 1:\n",
    "                y_true_scaled = tf.nn.avg_pool2d(y_true, scale, scale, 'VALID')\n",
    "                y_pred_scaled = tf.nn.avg_pool2d(y_pred, scale, scale, 'VALID')\n",
    "            else:\n",
    "                y_true_scaled = y_true\n",
    "                y_pred_scaled = y_pred\n",
    "                \n",
    "            true_grads = tf.image.sobel_edges(y_true_scaled)\n",
    "            pred_grads = tf.image.sobel_edges(y_pred_scaled)\n",
    "            grad_loss += tf.reduce_mean(tf.abs(true_grads - pred_grads))\n",
    "        \n",
    "        # Physics loss with adaptive weight\n",
    "        physics_loss = self.physics_consistency_loss(y_pred)\n",
    "        physics_weight = tf.minimum(1.0, tf.cast(self.running_gen_loss, tf.float32) / 2.0)\n",
    "        \n",
    "        # Dynamically adjust weights based on running losses\n",
    "        l1_weight = 50.0  # Reduced from 100.0\n",
    "        grad_weight = 10.0  # Reduced from 25.0\n",
    "        \n",
    "        total_loss = (\n",
    "            self.adversarial_weight * adversarial_loss + \n",
    "            l1_weight * l1_loss +\n",
    "            grad_weight * grad_loss + \n",
    "            physics_weight * self.lambda_physics * physics_loss\n",
    "        )\n",
    "        \n",
    "        # Update running average of generator loss\n",
    "        self.running_gen_loss.assign(\n",
    "            self.beta * self.running_gen_loss + (1 - self.beta) * total_loss\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'total_loss': total_loss,\n",
    "            'adversarial_loss': adversarial_loss,\n",
    "            'l1_loss': l1_loss,\n",
    "            'grad_loss': grad_loss,\n",
    "            'physics_loss': physics_loss,\n",
    "            'physics_weight': physics_weight\n",
    "        }\n",
    "    \n",
    "    def discriminator_loss(self, disc_real_output, disc_generated_output, \n",
    "                          real_images, generated_images, batch_size):\n",
    "        # Use least squares GAN loss for discriminator\n",
    "        real_loss = tf.reduce_mean(tf.square(disc_real_output - 1.0))\n",
    "        fake_loss = tf.reduce_mean(tf.square(disc_generated_output))\n",
    "        \n",
    "        # Calculate gradient penalty with adaptive weight\n",
    "        gp = self.gradient_penalty(real_images, generated_images, batch_size)\n",
    "        gp_weight = tf.minimum(10.0, 2.0 * tf.cast(self.running_disc_loss, tf.float32))\n",
    "        \n",
    "        total_loss = real_loss + fake_loss + gp_weight * gp\n",
    "        \n",
    "        # Update running average of discriminator loss\n",
    "        self.running_disc_loss.assign(\n",
    "            self.beta * self.running_disc_loss + (1 - self.beta) * total_loss\n",
    "        )\n",
    "        \n",
    "        # Adjust adversarial weight for generator based on discriminator performance\n",
    "        disc_ratio = real_loss / (fake_loss + 1e-6)\n",
    "        self.adversarial_weight.assign(\n",
    "            tf.clip_by_value(self.adversarial_weight * tf.sqrt(disc_ratio), 0.5, 2.0)\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'total_loss': total_loss,\n",
    "            'real_loss': real_loss,\n",
    "            'fake_loss': fake_loss,\n",
    "            'gradient_penalty': gp,\n",
    "            'gp_weight': gp_weight\n",
    "        }\n",
    "    \n",
    "    def physics_consistency_loss(self, y_pred):\n",
    "        \"\"\"Physics-based loss focusing on fluid dynamics constraints\"\"\"\n",
    "        # Calculate velocity gradients using central differences\n",
    "        dx = (y_pred[:, 2:, 1:-1, :] - y_pred[:, :-2, 1:-1, :]) / 2.0\n",
    "        dy = (y_pred[:, 1:-1, 2:, :] - y_pred[:, 1:-1, :-2, :]) / 2.0\n",
    "        \n",
    "        # Divergence-free constraint\n",
    "        divergence = dx + dy\n",
    "        divergence_loss = tf.reduce_mean(tf.square(divergence))\n",
    "        \n",
    "        # Add smoothness constraint for better stability\n",
    "        smoothness_loss = tf.reduce_mean(tf.square(dx)) + tf.reduce_mean(tf.square(dy))\n",
    "        \n",
    "        # Boundary conditions\n",
    "        boundary_loss = tf.reduce_mean(tf.square(y_pred[:, 0, :, :]) + \n",
    "                                     tf.square(y_pred[:, -1, :, :]) +\n",
    "                                     tf.square(y_pred[:, :, 0, :]) + \n",
    "                                     tf.square(y_pred[:, :, -1, :]))\n",
    "        \n",
    "        return divergence_loss + 0.1 * smoothness_loss + 0.05 * boundary_loss\n",
    "    \n",
    "    def gradient_penalty(self, real_images, fake_images, batch_size):\n",
    "        \"\"\"Calculate gradient penalty with improved interpolation\"\"\"\n",
    "        # Use random interpolation points\n",
    "        alpha = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(interpolated)\n",
    "            disc_interpolated = self.discriminator([interpolated, real_images], \n",
    "                                                 training=True)\n",
    "        \n",
    "        gradients = tape.gradient(disc_interpolated, interpolated)\n",
    "        slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]) + 1e-8)\n",
    "        return tf.reduce_mean(tf.square(slopes - 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bd813a-dc0b-44c0-958d-f3d1488a4a26",
   "metadata": {},
   "source": [
    "# Training setup\n",
    "An object containing all the necessary capabilities to train the model and preview progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7c5dd2-5632-4e86-90ca-a191e8625f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_images(model, test_input, tar):\n",
    "    \"\"\" Generates and displays a comparison between input image, \n",
    "    ground truth and predicted image from a model.\n",
    "    \"\"\"\n",
    "    # Remove any extra batch dimensions if present\n",
    "    if len(test_input.shape) > 4:\n",
    "        test_input = tf.squeeze(test_input, axis=0)\n",
    "    if len(tar.shape) > 4:\n",
    "        tar = tf.squeeze(tar, axis=0)\n",
    "    \n",
    "    # Add batch dimension if needed\n",
    "    if len(test_input.shape) == 3:\n",
    "        test_input = tf.expand_dims(test_input, 0)\n",
    "    if len(tar.shape) == 3:\n",
    "        tar = tf.expand_dims(tar, 0)\n",
    "    \n",
    "    prediction = model(test_input, training=True)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    value_range = .05\n",
    "    \n",
    "    display_list = [\n",
    "        test_input[0][:,:,0], tar[0][:,:,0], prediction[0][:,:,0],\n",
    "        test_input[0][:,:,1], tar[0][:,:,1], prediction[0][:,:,1],\n",
    "        test_input[0][:,:,2], tar[0][:,:,2], prediction[0][:,:,2] \n",
    "    ]\n",
    "    \n",
    "    maintitle = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "    title = ['vel.x', 'vel.y', 'pressure']\n",
    "    \n",
    "    for i in range(9):\n",
    "        plt_idx = i\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        \n",
    "        try: \n",
    "            header = f\"----- {maintitle[i]} -----\"\n",
    "        except: \n",
    "            header = \"\"\n",
    "        plt.title(f\"{header}\\n\\n{title[i//3]}\", fontsize=11)\n",
    "        \n",
    "        # Getting the pixel values in the [0, 1] range to plot.\n",
    "        tile = display_list[i]\n",
    "        plt.imshow(tile, vmin=-value_range, vmax=value_range)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e5b241-2933-447b-9bec-7a4c77bc0659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class DataAugmentor:\n",
    "    def __init__(self, min_size=64, max_size=104):\n",
    "        self.min_size = min_size\n",
    "        self.max_size = max_size\n",
    "\n",
    "    @tf.function\n",
    "    def augment(self, input_image, target_image):\n",
    "        \"\"\"Apply consistent augmentations to both input and target\"\"\"\n",
    "\n",
    "        # Generate random parameters once to apply same transformation to both\n",
    "        do_flip_lr = tf.random.uniform([]) > 0.5\n",
    "        do_flip_ud = tf.random.uniform([]) > 0.5\n",
    "        rotation_factor = tf.random.uniform([], 0, 4, dtype=tf.int32)\n",
    "\n",
    "        height = tf.random.uniform([], self.min_size, self.max_size, dtype=tf.int32)\n",
    "        width = tf.random.uniform([], self.min_size, self.max_size, dtype=tf.int32)\n",
    "\n",
    "        # Apply same transformations to both images\n",
    "        for image in [input_image, target_image]:\n",
    "            if do_flip_lr:\n",
    "                image = tf.image.flip_left_right(image)\n",
    "            if do_flip_ud:\n",
    "                image = tf.image.flip_up_down(image)\n",
    "            image = tf.image.rot90(image, k=rotation_factor)\n",
    "            image = tf.image.resize(image, [height, width])\n",
    "            image = tf.image.resize(image, [64, 64])  # Final consistent size\n",
    "\n",
    "        return input_image, target_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe24a63-c080-4e80-b143-a02a85ea1d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "class FluidGANTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        generator,\n",
    "        discriminator,\n",
    "        train_dataset,\n",
    "        test_dataset,\n",
    "        checkpoint_dir='./training_checkpoints',\n",
    "        preview_interval=10,\n",
    "        checkpoint_interval=50,\n",
    "        validation_interval=5,\n",
    "        reaugment_interval=5,  # Re-augment every N epochs\n",
    "        augmentation_factor=2,  # Number of augmented versions per original sample\n",
    "        samples_per_epoch=3000,\n",
    "        batch_size=10,\n",
    "        log_rate=200, # log every N batches\n",
    "        cache_dir='/tmp/tf_cache'\n",
    "    ):\n",
    "        # Existing initialization code\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.raw_train_dataset = train_dataset\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.preview_interval = preview_interval\n",
    "        self.checkpoint_interval = checkpoint_interval\n",
    "        self.validation_interval = validation_interval\n",
    "        self.reaugment_interval = reaugment_interval\n",
    "        self.augmentation_factor = augmentation_factor\n",
    "        self.samples_per_epoch = samples_per_epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.log_rate = log_rate\n",
    "        self.cache_dir = cache_dir\n",
    "        \n",
    "        # Initialize data augmentor\n",
    "        self.augmentor = DataAugmentor()\n",
    "        \n",
    "        # Setup augmented datasets\n",
    "        self.train_dataset = None  # Will be initialized in setup_training_dataset\n",
    "        self.test_dataset = self._setup_augmented_dataset(test_dataset, is_training=False)\n",
    "        \n",
    "        # Add learning rate scheduling\n",
    "        initial_lr_gen = 5e-5 * batch_size\n",
    "        initial_lr_disc = 1e-5 * batch_size\n",
    "        self.generator_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_lr_gen, decay_steps=2000, decay_rate=0.98, staircase=True)\n",
    "        self.discriminator_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_lr_disc, decay_steps=2000, decay_rate=0.98, staircase=True)\n",
    "        \n",
    "        # Initialize optimizers\n",
    "        self.generator_optimizer = tf.keras.optimizers.Adam(\n",
    "            self.generator_scheduler, beta_1=0.5, beta_2=0.9)\n",
    "        self.discriminator_optimizer = tf.keras.optimizers.Adam(\n",
    "            self.discriminator_scheduler, beta_1=0.0, beta_2=0.9, epsilon=1e-8)\n",
    "        \n",
    "        # Initialize loss function\n",
    "        self.loss_fn = FluidGANLoss(discriminator=self.discriminator, lambda_gp=10.0, lambda_physics=0.0)\n",
    "        \n",
    "        # Setup checkpointing\n",
    "        self.checkpoint = tf.train.Checkpoint(\n",
    "            generator_optimizer=self.generator_optimizer,\n",
    "            discriminator_optimizer=self.discriminator_optimizer,\n",
    "            generator=self.generator,\n",
    "            discriminator=self.discriminator\n",
    "        )\n",
    "        self.checkpoint_manager = tf.train.CheckpointManager(\n",
    "            self.checkpoint, self.checkpoint_dir, max_to_keep=10\n",
    "        )\n",
    "        \n",
    "        # Setup logging\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.log_dir = f'logs/{current_time}'\n",
    "        self.summary_writer = tf.summary.create_file_writer(self.log_dir)\n",
    "\n",
    "    def _setup_augmented_dataset(self, dataset, is_training=True):\n",
    "        \"\"\"Setup cached and augmented dataset\"\"\"\n",
    "        if not isinstance(dataset, tf.data.Dataset):\n",
    "            dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "        \n",
    "        if is_training:\n",
    "            # For training: repeat -> shuffle -> augment -> batch -> cache -> prefetch\n",
    "            pipeline = (dataset\n",
    "                .repeat(self.augmentation_factor)  # Repeat dataset to allow for more augmentations\n",
    "                .shuffle(1000 * self.augmentation_factor)  # Increase shuffle buffer for larger dataset\n",
    "                .map(self.augmentor.augment, \n",
    "                     num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                .batch(self.batch_size)\n",
    "                .cache()  # Cache after batching\n",
    "                .prefetch(tf.data.AUTOTUNE))\n",
    "        else:\n",
    "            # For testing: batch -> cache -> prefetch\n",
    "            pipeline = (dataset\n",
    "                .batch(self.batch_size)\n",
    "                .cache()  # Cache after batching\n",
    "                .prefetch(tf.data.AUTOTUNE))\n",
    "        \n",
    "        return pipeline\n",
    "    \n",
    "    def setup_training_dataset(self, epoch):\n",
    "        \"\"\"Setup or refresh training dataset with new augmentations\"\"\"\n",
    "        cache_path = f\"{self.cache_dir}/train_epoch_{epoch // self.reaugment_interval}\"\n",
    "        \n",
    "        # Clear previous cached datasets if they exist\n",
    "        try:\n",
    "            tf.io.gfile.rmtree(f\"{self.cache_dir}/train_epoch_{(epoch // self.reaugment_interval) - 1}\")\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        print(f\"Setting up new augmented dataset for epochs {epoch+1}-{epoch+1 + self.reaugment_interval - 1}\")\n",
    "        print(f\"Creating augmented dataset with {self.augmentation_factor}x augmentation \"\n",
    "              f\"(from {len(self.raw_train_dataset)} to {len(self.raw_train_dataset) * self.augmentation_factor} samples)\")\n",
    "        \n",
    "        self.train_dataset = self._setup_augmented_dataset(\n",
    "            self.raw_train_dataset, \n",
    "            is_training=True\n",
    "        )\n",
    "    \n",
    "    def get_epoch_dataset(self, num_samples):\n",
    "        \"\"\"Get samples for one epoch\"\"\"\n",
    "        # Calculate actual number of batches needed\n",
    "        total_samples = len(self.raw_train_dataset) * self.augmentation_factor\n",
    "        num_batches = min(num_samples, total_samples) // self.batch_size\n",
    "        \n",
    "        # Since dataset is already batched and cached, we just need to shuffle and take\n",
    "        return (self.train_dataset\n",
    "            .shuffle(num_batches)  # Shuffle at batch level\n",
    "            .take(num_batches)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "    \n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, input_image, target_image):\n",
    "        \"\"\"Single training step\"\"\"\n",
    "        batch_size = tf.shape(input_image)[0]\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            # Generator forward pass\n",
    "            gen_output = self.generator(input_image, training=True)\n",
    "            \n",
    "            # Discriminator forward passes\n",
    "            disc_real_output = self.discriminator([input_image, target_image], training=True)\n",
    "            disc_generated_output = self.discriminator([input_image, gen_output], training=True)\n",
    "            \n",
    "            # Calculate losses\n",
    "            gen_losses = self.loss_fn.generator_loss(\n",
    "                disc_generated_output, target_image, gen_output\n",
    "            )\n",
    "            disc_losses = self.loss_fn.discriminator_loss(\n",
    "                disc_real_output, disc_generated_output,\n",
    "                target_image, gen_output, batch_size\n",
    "            )\n",
    "        \n",
    "        # Calculate gradients\n",
    "        generator_gradients = gen_tape.gradient(\n",
    "            gen_losses['total_loss'],\n",
    "            self.generator.trainable_variables\n",
    "        )\n",
    "        discriminator_gradients = disc_tape.gradient(\n",
    "            disc_losses['total_loss'],\n",
    "            self.discriminator.trainable_variables\n",
    "        )\n",
    "        \n",
    "        # Apply gradient clipping\n",
    "        generator_gradients = [tf.clip_by_norm(g, 1.0) for g in generator_gradients]\n",
    "        discriminator_gradients = [tf.clip_by_norm(g, 1.0) for g in discriminator_gradients]\n",
    "        \n",
    "        # Apply gradients\n",
    "        self.generator_optimizer.apply_gradients(\n",
    "            zip(generator_gradients, self.generator.trainable_variables)\n",
    "        )\n",
    "        self.discriminator_optimizer.apply_gradients(\n",
    "            zip(discriminator_gradients, self.discriminator.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        return gen_losses, disc_losses\n",
    "\n",
    "    \n",
    "    @tf.function\n",
    "    def validation_step(self, input_image, target_image):\n",
    "        \"\"\"Single validation step without gradient updates\"\"\"\n",
    "        batch_size = tf.shape(input_image)[0]\n",
    "        \n",
    "        # Generator forward pass\n",
    "        gen_output = self.generator(input_image, training=False)\n",
    "        \n",
    "        # Discriminator forward passes\n",
    "        disc_real_output = self.discriminator([input_image, target_image], training=False)\n",
    "        disc_generated_output = self.discriminator([input_image, gen_output], training=False)\n",
    "        \n",
    "        # Calculate losses\n",
    "        gen_losses = self.loss_fn.generator_loss(\n",
    "            disc_generated_output, target_image, gen_output\n",
    "        )\n",
    "        disc_losses = self.loss_fn.discriminator_loss(\n",
    "            disc_real_output, disc_generated_output,\n",
    "            target_image, gen_output, batch_size\n",
    "        )\n",
    "        \n",
    "        return gen_losses, disc_losses\n",
    "\n",
    "    def validate_model(self):\n",
    "        \"\"\"Run validation on the test dataset\"\"\"\n",
    "        total_gen_loss = 0\n",
    "        total_disc_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for input_image, target_image in self.test_dataset:\n",
    "            gen_losses, disc_losses = self.validation_step(input_image, target_image)\n",
    "            total_gen_loss += gen_losses['total_loss']\n",
    "            total_disc_loss += disc_losses['total_loss']\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_gen_loss = total_gen_loss / num_batches\n",
    "        avg_disc_loss = total_disc_loss / num_batches\n",
    "        \n",
    "        return {\n",
    "            'generator_loss': avg_gen_loss,\n",
    "            'discriminator_loss': avg_disc_loss\n",
    "        }\n",
    "\n",
    "    def train(self, epochs):\n",
    "        \"\"\"Main training loop with periodic re-augmentation\"\"\"\n",
    "        start = time.time()\n",
    "        \n",
    "        # Try to restore latest checkpoint\n",
    "        if self.checkpoint_manager.latest_checkpoint:\n",
    "            self.checkpoint.restore(self.checkpoint_manager.latest_checkpoint)\n",
    "            print(f'Latest checkpoint restored from {self.checkpoint_manager.latest_checkpoint}')\n",
    "        \n",
    "        test_input, test_target = next(iter(self.test_dataset.batch(1)))\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Re-augment dataset every reaugment_interval epochs\n",
    "            if epoch % self.reaugment_interval == 0:\n",
    "                self.setup_training_dataset(epoch)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Get batched dataset for this epoch\n",
    "            epoch_dataset = self.get_epoch_dataset(self.samples_per_epoch)\n",
    "            \n",
    "            # Train on batches\n",
    "            for batch_idx, (input_image, target_image) in enumerate(epoch_dataset):\n",
    "                gen_losses, disc_losses = self.train_step(input_image, target_image)\n",
    "                \n",
    "                # Log every @log_rate batches\n",
    "                if batch_idx % self.log_rate == 0:\n",
    "                    print(f'Epoch {epoch+1}, Batch {batch_idx}:')\n",
    "                    gen_lr = self.generator_scheduler(self.generator_optimizer.iterations)\n",
    "                    disc_lr = self.discriminator_scheduler(self.discriminator_optimizer.iterations)\n",
    "                    print(f'Generator Loss: {gen_losses[\"total_loss\"]:.4f},  LR: {gen_lr:.2e}')\n",
    "                    print(f'Discriminator Loss: {disc_losses[\"total_loss\"]:.4f},  LR: {disc_lr:.2e}')\n",
    "                    \n",
    "                    # Log to TensorBoard\n",
    "                    with self.summary_writer.as_default():\n",
    "                        step = epoch * (self.samples_per_epoch // self.batch_size) + batch_idx\n",
    "                        tf.summary.scalar('train/gen_total_loss', gen_losses['total_loss'], step=step)\n",
    "                        tf.summary.scalar('train/gen_adversarial_loss', gen_losses['adversarial_loss'], step=step)\n",
    "                        tf.summary.scalar('train/l1_loss', gen_losses['l1_loss'], step=step)\n",
    "                        tf.summary.scalar('train/gen_physics_loss', gen_losses['physics_loss'], step=step)\n",
    "                        tf.summary.scalar('train/disc_total_loss', disc_losses['total_loss'], step=step)\n",
    "\n",
    "            \n",
    "            # Run validation\n",
    "            if (epoch + 1) % self.validation_interval == 0:\n",
    "                val_losses = self.validate_model()\n",
    "                print(f'Validation Losses:')\n",
    "                print(f'Generator Loss: {val_losses[\"generator_loss\"]:.4f}')\n",
    "                print(f'Discriminator Loss: {val_losses[\"discriminator_loss\"]:.4f}')\n",
    "                \n",
    "                # Log validation metrics\n",
    "                with self.summary_writer.as_default():\n",
    "                    tf.summary.scalar('validation/gen_loss', val_losses['generator_loss'], step=(epoch + 1))\n",
    "                    tf.summary.scalar('validation/disc_loss', val_losses['discriminator_loss'], step=(epoch + 1))\n",
    "            \n",
    "            # Preview images\n",
    "            if (epoch + 1) % self.preview_interval == 0:\n",
    "                generate_images(self.generator, test_input, test_target)\n",
    "            \n",
    "            # Save checkpoint\n",
    "            if (epoch + 1) % self.checkpoint_interval == 0:\n",
    "                self.checkpoint_manager.save()\n",
    "                print(f'Checkpoint saved for epoch {epoch+1}')\n",
    "            \n",
    "            print(f'Epoch {epoch+1} took {time.time()-start_time:.2f} seconds')\n",
    "        \n",
    "        print(f'Training took {time.time()-start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce705e8-a3d5-4780-b71d-76218a77f8c0",
   "metadata": {},
   "source": [
    "# Ingest Data, build datasets, run training\n",
    "Load concatenated data output by \"pressure_predict_1_data_prep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a0c4a-69c2-4415-9717-c6535bb9e37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "# combined_data_path = \"./data2D/loaded_data_v2_rand.npz\" # Original approach with pre-augmented data\n",
    "combined_data_path = \"./data2D/loaded_data_v2.npz\" # Original dataset with ~1600 datapoints of 111x111 size\n",
    "with np.load(combined_data_path) as data:\n",
    "    X_train = data[\"X_train\"]\n",
    "    Y_train = data[\"Y_train\"]\n",
    "    X_test  = data[\"X_test\"]\n",
    "    Y_test  = data[\"Y_test\"]\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Loaded combined array in {end_time - start_time:.2f} seconds.\")\n",
    "print(\"Loaded X shape: \", np.array(X_train).shape, np.array(X_test).shape)\n",
    "print(\"Loaded Y shape: \", np.array(Y_train).shape, np.array(Y_test).shape)\n",
    "\n",
    "# Normally returns:\n",
    "# Loaded X shape:  (5000, 64, 64, 3) (1000, 64, 64, 3)\n",
    "# Loaded Y shape:  (5000, 64, 64, 3) (1000, 64, 64, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423df2df-ba2a-4cc8-823e-527da730bec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test untrained generator and preview.\n",
    "prev_idx = 10\n",
    "generate_images(generator, X_train[prev_idx][tf.newaxis, ...], Y_train[prev_idx][tf.newaxis, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db3ba2-2854-4cfd-abb0-8061abcd54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY BATCHING (with 1)\n",
    "# ... and achieve output dimensionality of:     [2,     n, 64, 64, 3] \n",
    "# ... with desired iteration dimensionality of:     [None, 64, 64, 3]\n",
    "import tensorflow as tf\n",
    "\n",
    "X_train = tf.cast(X_train, tf.float32)\n",
    "Y_train = tf.cast(Y_train, tf.float32)\n",
    "X_test = tf.cast(X_test, tf.float32)\n",
    "Y_test = tf.cast(Y_test, tf.float32)\n",
    "\n",
    "# Normalize data to [-1, 1] range if not already done\n",
    "# def normalize(x):\n",
    "#     return tf.clip_by_value(x, -1, 1)\n",
    "\n",
    "# X_train, Y_train = normalize(X_train), normalize(Y_train)\n",
    "# X_test, Y_test = normalize(X_test), normalize(Y_test)\n",
    "\n",
    "# Create datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "train_ds = train_ds.shuffle(5000)\n",
    "#train_ds = train_ds.batch(5)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
    "test_ds = test_ds.shuffle(1000)\n",
    "#test_ds = test_ds.batch(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f40237-0be3-455b-aeb3-9d773aafb584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "log_dir = \"./logs\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "random_port = random.randrange(1001,9900)\n",
    "print(f\"Loading tensorboard on port: {random_port}\")\n",
    "%tensorboard --logdir={log_dir} --reload_multifile=true --port={random_port} --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04bf7c2-fc28-4a9f-8d89-92d9e78e7984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = FluidGANTrainer(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    train_dataset=train_ds,\n",
    "    test_dataset=test_ds,\n",
    "    checkpoint_dir='./training_checkpointsH',\n",
    "    preview_interval=10,\n",
    "    checkpoint_interval=20,\n",
    "    validation_interval=10,\n",
    "    reaugment_interval=10,\n",
    "    augmentation_factor=2,\n",
    "    samples_per_epoch=3000,\n",
    "    batch_size=10,\n",
    "    log_rate=100\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train(epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb143d-9415-4edc-a28f-27ffc7c3f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netron\n",
    "model = \"./models/pressure_predict_D_v0.h5\"\n",
    "netron.start(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4881d0b9-e4b3-40d3-8dd2-ca9ccd4d551b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
