{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e5c84fc-01bd-4802-82c5-fe73aa4d643d",
   "metadata": {},
   "source": [
    "# Model Export\n",
    "1) Re-Build generator architecture\n",
    "2) Reload trained weights from checkpoint\n",
    "3) export with ONNX\n",
    "\n",
    "### 1) Model Reinitialization\n",
    "Copy from Model Build/Train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "091f055b-d4af-40e5-af3c-00fdad56fd12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 21:21:45.183186: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-05 21:21:45.183285: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-05 21:21:45.183510: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-05 21:21:45.215172: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "def attention_block(x, filters):\n",
    "    \"\"\"Self-attention mechanism with dynamic input support\"\"\"\n",
    "    shape = tf.shape(x)\n",
    "    batch_size, height, width = shape[0], shape[1], shape[2]\n",
    "    \n",
    "    f = tf.keras.layers.Conv2D(filters // 8, 1)(x)\n",
    "    g = tf.keras.layers.Conv2D(filters // 8, 1)(x)\n",
    "    h = tf.keras.layers.Conv2D(filters, 1)(x)\n",
    "    \n",
    "    f = tf.reshape(f, [batch_size, -1, filters // 8])\n",
    "    g = tf.reshape(g, [batch_size, -1, filters // 8])\n",
    "    h = tf.reshape(h, [batch_size, -1, filters])\n",
    "    \n",
    "    s = tf.matmul(f, g, transpose_b=True)\n",
    "    beta = tf.nn.softmax(s)\n",
    "    \n",
    "    o = tf.matmul(beta, h)\n",
    "    o = tf.reshape(o, [batch_size, height, width, filters])\n",
    "    \n",
    "    gamma = tf.Variable(0.0, trainable=True)\n",
    "    return x + gamma * o\n",
    "\n",
    "def spectral_conv2d(filters, kernel_size, strides=1):\n",
    "    return tf.keras.layers.Conv2D(\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        strides=strides,\n",
    "        padding='same',\n",
    "        kernel_initializer='orthogonal',\n",
    "        use_bias=False\n",
    "    )\n",
    "\n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(spectral_conv2d(filters, size, strides=2))\n",
    "    \n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization(momentum=0.9))\n",
    "    \n",
    "    result.add(tf.keras.layers.PReLU(shared_axes=[1, 2]))\n",
    "    return result\n",
    "\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2DTranspose(\n",
    "            filters, size, strides=2,\n",
    "            padding='same',\n",
    "            kernel_initializer='orthogonal',\n",
    "            use_bias=False\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    result.add(tf.keras.layers.LayerNormalization())\n",
    "    \n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.SpatialDropout2D(0.5))\n",
    "    \n",
    "    result.add(tf.keras.layers.PReLU(shared_axes=[1, 2]))\n",
    "    return result\n",
    "\n",
    "def resnet_block(input_tensor, filters, kernel_size=3):\n",
    "    def squeeze_excite_block(input_tensor, ratio=16):\n",
    "        channels = input_tensor.shape[-1]\n",
    "        \n",
    "        se = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
    "        se = tf.keras.layers.Reshape((1, 1, channels))(se)\n",
    "        se = tf.keras.layers.Dense(channels // ratio, activation='relu')(se)\n",
    "        se = tf.keras.layers.Dense(channels, activation='sigmoid')(se)\n",
    "        \n",
    "        return tf.keras.layers.Multiply()([input_tensor, se])\n",
    "    \n",
    "    x = spectral_conv2d(filters, kernel_size)(input_tensor)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    \n",
    "    x = spectral_conv2d(filters, kernel_size)(x)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    \n",
    "    x = squeeze_excite_block(x)\n",
    "    x = tf.keras.layers.Add()([x, input_tensor])\n",
    "    x = tf.keras.layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bfc2366-d168-41b2-9674-1d444f4cc0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "\n",
    "@register_keras_serializable(package=\"CustomLayers\")\n",
    "class DynamicPaddingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, target_multiple=8, **kwargs):\n",
    "        super(DynamicPaddingLayer, self).__init__(**kwargs)\n",
    "        self.target_multiple = target_multiple\n",
    "        self.built = False\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # No dynamic padding weights needed for fixed 64x64 input\n",
    "        self.built = True\n",
    "        super(DynamicPaddingLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Fixed padding for 64x64 input to match a multiple of 8\n",
    "        paddings = tf.convert_to_tensor([\n",
    "            [0, 0],  # Batch dimension\n",
    "            [0, 0],  # Height (no padding needed for 64)\n",
    "            [0, 0],  # Width (no padding needed for 64)\n",
    "            [0, 0]   # Channels dimension\n",
    "        ], dtype=tf.int32)\n",
    "        \n",
    "        return tf.pad(inputs, paddings, mode='REFLECT')\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(DynamicPaddingLayer, self).get_config()\n",
    "        config.update({\n",
    "            'target_multiple': self.target_multiple\n",
    "        })\n",
    "        return config\n",
    "\n",
    "@register_keras_serializable(package=\"CustomLayers\")\n",
    "class UnpadLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, padding_layer=None, **kwargs):\n",
    "        super(UnpadLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # No unpadding needed for 64x64 input\n",
    "        return inputs\n",
    "    \n",
    "    def get_config(self):\n",
    "        return super(UnpadLayer, self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0344acea-bcc7-407c-9418-37979e34b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(input_shape=(None, None, 3)):\n",
    "    \"\"\"Build generator with support for arbitrary input sizes\"\"\"\n",
    "    tf.keras.backend.set_floatx('float32')\n",
    "    \n",
    "    # Input layer\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Add padding layer\n",
    "    padding_layer = DynamicPaddingLayer(target_multiple=8)\n",
    "    x = padding_layer(inputs)\n",
    "    \n",
    "    # Initial convolution\n",
    "    x = spectral_conv2d(32, 7)(x)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    \n",
    "    # Downsampling path\n",
    "    down_stack = [\n",
    "        downsample(64, 3, apply_batchnorm=False),\n",
    "        downsample(128, 3),\n",
    "        downsample(256, 3),\n",
    "    ]\n",
    "    \n",
    "    # Store skip connections\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "    \n",
    "    # ResNet blocks\n",
    "    num_res_blocks = 9\n",
    "    for i in range(num_res_blocks):\n",
    "        x = resnet_block(x, filters=256)\n",
    "        if i % 2 == 0:\n",
    "            x = attention_block(x, filters=256)\n",
    "    \n",
    "    # Upsampling path\n",
    "    up_stack = [\n",
    "        upsample(128, 3, apply_dropout=True),\n",
    "        upsample(64, 3),\n",
    "        upsample(32, 3),\n",
    "    ]\n",
    "    \n",
    "    # Decoder with skip connections\n",
    "    skips = reversed(skips[:-1])\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = attention_block(x, x.shape[-1])\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "    \n",
    "    # Final output layer\n",
    "    x = tf.keras.layers.Conv2DTranspose(\n",
    "        3, 4,\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        kernel_initializer='orthogonal',\n",
    "        activation='tanh'\n",
    "    )(x)\n",
    "    \n",
    "    # Remove padding using custom unpad layer\n",
    "    outputs = UnpadLayer(padding_layer)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a2c301-12e5-471b-991b-77a8222fe9e2",
   "metadata": {},
   "source": [
    "### 2) Reload trained weights\n",
    "from checkpoint exported from training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7db29e-ab54-4799-9e44-5b120645fb87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Define the checkpoint directory\n",
    "checkpoint_dir = './training_checkpointsH'\n",
    "\n",
    "# Initialize generator model\n",
    "generator = build_generator(input_shape=(None, None, 3)) \n",
    "\n",
    "# Create a checkpoint object for the generator only\n",
    "checkpoint = tf.train.Checkpoint(generator=generator)\n",
    "\n",
    "# Restore the latest checkpoint\n",
    "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "if latest_checkpoint:\n",
    "    checkpoint.restore(latest_checkpoint).expect_partial()\n",
    "    print(f\"Checkpoint restored from {latest_checkpoint}\")\n",
    "else:\n",
    "    # Debug: Print contents of the directory\n",
    "    print(\"Contents of checkpoint directory:\")\n",
    "    print(os.listdir(checkpoint_dir))\n",
    "    print(\"No checkpoint found.\")\n",
    "\n",
    "# Export saving generator\n",
    "generator.save('./models/pressure_predict_H.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db26702e-3787-4a4d-bd71-58441b4a44c8",
   "metadata": {},
   "source": [
    "### 3) ONNX export\n",
    "convert to onnx framework and export to disk to be evaluated in Houdini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6acc7da-1411-4001-a047-e7a0f9dc5853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "import onnx\n",
    "\n",
    "def export_to_onnx(model_path, output_path):\n",
    "    \"\"\"\n",
    "    Helper function to export saved model to ONNX format with dynamic input shapes\n",
    "    Handles conversion from NHWC (TensorFlow) to NCHW (ONNX) format while preserving padding\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the saved model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Create a wrapper model that handles the NHWC->NCHW conversion explicitly\n",
    "    input_layer = tf.keras.layers.Input(shape=(None, None, 3), name=\"input_nhwc\")\n",
    "    \n",
    "    # Convert NHWC to NCHW before model\n",
    "    x = tf.transpose(input_layer, [0, 3, 1, 2], name=\"to_nchw\")\n",
    "    \n",
    "    # Run through model\n",
    "    output = model(x)\n",
    "    \n",
    "    # Convert back to NHWC for proper padding handling\n",
    "    output = tf.transpose(output, [0, 2, 3, 1], name=\"to_nhwc\")\n",
    "    \n",
    "    wrapper_model = tf.keras.Model(inputs=input_layer, outputs=output)\n",
    "    \n",
    "    # Use NCHW format with dynamic spatial dimensions\n",
    "    input_signature = [tf.TensorSpec([None, None, None, 3], tf.float32, name=\"input\")]\n",
    "    \n",
    "    # Convert to ONNX without automatic NCHW conversion\n",
    "    model_proto, external_tensor_storage = tf2onnx.convert.from_keras(\n",
    "        wrapper_model, \n",
    "        input_signature=input_signature,\n",
    "        opset=13\n",
    "    )\n",
    "    \n",
    "    # Function to set shape parameters\n",
    "    def set_shape_params(tensor):\n",
    "        shape = tensor.type.tensor_type.shape\n",
    "        # Make batch dimension dynamic\n",
    "        shape.dim[0].dim_value = 0\n",
    "        shape.dim[0].dim_param = \"batch\"\n",
    "        # Set channel dimension (3 for RGB)\n",
    "        shape.dim[1].dim_value = 3\n",
    "        # Make spatial dimensions dynamic\n",
    "        shape.dim[2].dim_value = 0\n",
    "        shape.dim[2].dim_param = \"height\"\n",
    "        shape.dim[3].dim_value = 0\n",
    "        shape.dim[3].dim_param = \"width\"\n",
    "    \n",
    "    # Modify input shapes\n",
    "    for tensor in model_proto.graph.input:\n",
    "        set_shape_params(tensor)\n",
    "    \n",
    "    # Modify output shapes\n",
    "    for tensor in model_proto.graph.output:\n",
    "        set_shape_params(tensor)\n",
    "    \n",
    "    # Save the ONNX model\n",
    "    onnx.save(model_proto, output_path)\n",
    "    \n",
    "    # Verify the exported model\n",
    "    onnx_model = onnx.load(output_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    \n",
    "    # Print model input/output shapes\n",
    "    print(f\"Model exported to {output_path}\")\n",
    "    print(\"\\nInput shapes:\")\n",
    "    for inp in onnx_model.graph.input:\n",
    "        print(f\"{inp.name}: {[d.dim_param if d.dim_param else d.dim_value for d in inp.type.tensor_type.shape.dim]}\")\n",
    "    print(\"\\nOutput shapes:\")\n",
    "    for out in onnx_model.graph.output:\n",
    "        print(f\"{out.name}: {[d.dim_param if d.dim_param else d.dim_value for d in out.type.tensor_type.shape.dim]}\")\n",
    "\n",
    "# Usage\n",
    "model_path = \"./models/pressure_predict_H.keras\"\n",
    "output_path = \"./models/pressure_predict_H3.onnx\"\n",
    "export_to_onnx(model_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ff321-d2a5-4607-8bae-27a312ab7719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "import onnx\n",
    "\n",
    "def export_to_onnx_static(model_path, output_path):\n",
    "    \"\"\"\n",
    "    Helper function to export saved model to ONNX format with fixed 64x64 input shape\n",
    "    Handles conversion from NHWC (TensorFlow) to NCHW (ONNX) format while preserving padding\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the saved model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Create a wrapper model that handles the NHWC->NCHW conversion explicitly\n",
    "    # Now with a fixed input shape of 64x64\n",
    "    input_layer = tf.keras.layers.Input(shape=(64, 64, 3), name=\"input_nhwc\")\n",
    "    \n",
    "    # Convert NHWC to NCHW before model\n",
    "    x = tf.transpose(input_layer, [0, 3, 1, 2], name=\"to_nchw\")\n",
    "    \n",
    "    # Run through model\n",
    "    output = model(x)\n",
    "    \n",
    "    # Convert back to NHWC for proper padding handling\n",
    "    output = tf.transpose(output, [0, 2, 3, 1], name=\"to_nhwc\")\n",
    "    \n",
    "    wrapper_model = tf.keras.Model(inputs=input_layer, outputs=output)\n",
    "    \n",
    "    # Use NCHW format with fixed 64x64 spatial dimensions\n",
    "    input_signature = [tf.TensorSpec([None, 64, 64, 3], tf.float32, name=\"input\")]\n",
    "    \n",
    "    # Convert to ONNX without automatic NCHW conversion\n",
    "    model_proto, external_tensor_storage = tf2onnx.convert.from_keras(\n",
    "        wrapper_model, \n",
    "        input_signature=input_signature,\n",
    "        opset=13\n",
    "    )\n",
    "    \n",
    "    # Function to set shape parameters with fixed 64x64 dimensions\n",
    "    def set_shape_params(tensor):\n",
    "        shape = tensor.type.tensor_type.shape\n",
    "        # Make batch dimension dynamic\n",
    "        shape.dim[0].dim_value = 0\n",
    "        shape.dim[0].dim_param = \"batch\"\n",
    "        # Set channel dimension (3 for RGB)\n",
    "        shape.dim[1].dim_value = 3\n",
    "        # Set fixed spatial dimensions to 64\n",
    "        shape.dim[2].dim_value = 64\n",
    "        shape.dim[3].dim_value = 64\n",
    "        # Remove any dynamic parameters for height and width\n",
    "        if len(shape.dim) > 2:\n",
    "            if hasattr(shape.dim[2], 'dim_param'):\n",
    "                del shape.dim[2].dim_param\n",
    "            if hasattr(shape.dim[3], 'dim_param'):\n",
    "                del shape.dim[3].dim_param\n",
    "    \n",
    "    # Modify input shapes\n",
    "    for tensor in model_proto.graph.input:\n",
    "        set_shape_params(tensor)\n",
    "    \n",
    "    # Modify output shapes\n",
    "    for tensor in model_proto.graph.output:\n",
    "        set_shape_params(tensor)\n",
    "    \n",
    "    # Save the ONNX model\n",
    "    onnx.save(model_proto, output_path)\n",
    "    \n",
    "    # Verify the exported model\n",
    "    onnx_model = onnx.load(output_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    \n",
    "    # Print model input/output shapes\n",
    "    print(f\"Model exported to {output_path}\")\n",
    "    print(\"\\nInput shapes:\")\n",
    "    for inp in onnx_model.graph.input:\n",
    "        print(f\"{inp.name}: {[d.dim_param if d.dim_param else d.dim_value for d in inp.type.tensor_type.shape.dim]}\")\n",
    "    print(\"\\nOutput shapes:\")\n",
    "    for out in onnx_model.graph.output:\n",
    "        print(f\"{out.name}: {[d.dim_param if d.dim_param else d.dim_value for d in out.type.tensor_type.shape.dim]}\")\n",
    "\n",
    "# Usage\n",
    "model_path = \"./models/pressure_predict_H.keras\"\n",
    "output_path = \"./models/pressure_predict_H_static.onnx\"\n",
    "export_to_onnx_static(model_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd99739-01db-4321-8a90-50fd86556791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "import onnx\n",
    "\n",
    "def export_to_onnx(model_path, output_path):\n",
    "    \"\"\"\n",
    "    Helper function to export saved model to ONNX format with fixed 64x64 input shape\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the saved model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Create a wrapper model that handles the input conversion explicitly\n",
    "    input_layer = tf.keras.layers.Input(shape=(8, 64, 64), name=\"input_nchw\")\n",
    "    \n",
    "    # Run through model directly with NCHW input\n",
    "    output = model(input_layer)\n",
    "    \n",
    "    wrapper_model = tf.keras.Model(inputs=input_layer, outputs=output)\n",
    "    \n",
    "    # Use fixed NCHW input shape\n",
    "    input_signature = [tf.TensorSpec([None, 8, 64, 64], tf.float32, name=\"input\")]\n",
    "    \n",
    "    # Convert to ONNX \n",
    "    model_proto, external_tensor_storage = tf2onnx.convert.from_keras(\n",
    "        wrapper_model, \n",
    "        input_signature=input_signature,\n",
    "        opset=13\n",
    "    )\n",
    "    \n",
    "    # Function to set shape parameters with fixed 64x64 dimensions\n",
    "    def set_shape_params(tensor):\n",
    "        shape = tensor.type.tensor_type.shape\n",
    "        # Make batch dimension dynamic\n",
    "        shape.dim[0].dim_value = 0\n",
    "        shape.dim[0].dim_param = \"batch\"\n",
    "        # Set channel dimension (8)\n",
    "        shape.dim[1].dim_value = 8\n",
    "        # Set fixed spatial dimensions to 64\n",
    "        shape.dim[2].dim_value = 64\n",
    "        shape.dim[3].dim_value = 64\n",
    "        # Remove any dynamic parameters\n",
    "        if len(shape.dim) > 2:\n",
    "            if hasattr(shape.dim[2], 'dim_param'):\n",
    "                del shape.dim[2].dim_param\n",
    "            if hasattr(shape.dim[3], 'dim_param'):\n",
    "                del shape.dim[3].dim_param\n",
    "    \n",
    "    # Modify input shapes\n",
    "    for tensor in model_proto.graph.input:\n",
    "        set_shape_params(tensor)\n",
    "    \n",
    "    # Modify output shapes\n",
    "    for tensor in model_proto.graph.output:\n",
    "        set_shape_params(tensor)\n",
    "    \n",
    "    # Save the ONNX model\n",
    "    onnx.save(model_proto, output_path)\n",
    "    \n",
    "    # Verify the exported model\n",
    "    onnx_model = onnx.load(output_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    \n",
    "    # Print model input/output shapes\n",
    "    print(f\"Model exported to {output_path}\")\n",
    "    print(\"\\nInput shapes:\")\n",
    "    for inp in onnx_model.graph.input:\n",
    "        print(f\"{inp.name}: {[d.dim_param if d.dim_param else d.dim_value for d in inp.type.tensor_type.shape.dim]}\")\n",
    "    print(\"\\nOutput shapes:\")\n",
    "    for out in onnx_model.graph.output:\n",
    "        print(f\"{out.name}: {[d.dim_param if d.dim_param else d.dim_value for d in out.type.tensor_type.shape.dim]}\")\n",
    "\n",
    "# Usage\n",
    "model_path = \"./models/pressure_predict_H.keras\"\n",
    "output_path = \"./models/pressure_predict_H_static.onnx\"\n",
    "export_to_onnx(model_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104bfde9-8ff0-4865-a771-f337d54b4dda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "def test_onnx_model_with_padding(model_path, sample_batch_size=1, sample_width=64, sample_height=64):\n",
    "    \"\"\"\n",
    "    Test an ONNX model with dynamic padding, checking for dimension handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        session = onnxruntime.InferenceSession(model_path, providers=['CPUExecutionProvider'])\n",
    "        \n",
    "        # Get model metadata\n",
    "        input_name = session.get_inputs()[0].name\n",
    "        input_shape = session.get_inputs()[0].shape\n",
    "        print(f\"Model input name: {input_name}\")\n",
    "        print(f\"Model input shape: {input_shape}\")\n",
    "        \n",
    "        # Test multiple input sizes to check padding behavior\n",
    "        test_sizes = [\n",
    "            (sample_height, sample_width),\n",
    "            (sample_height + 1, sample_width + 1),  # Non-multiple of 8\n",
    "            (sample_height - 1, sample_width - 1),  # Non-multiple of 8\n",
    "            (64, 64),  # Multiple of 8\n",
    "            (72, 72)   # Multiple of 8\n",
    "        ]\n",
    "        \n",
    "        for height, width in test_sizes:\n",
    "            print(f\"\\nTesting input size: {height}x{width}\")\n",
    "            sample_input = np.random.randn(sample_batch_size, 3, height, width).astype(np.float32)\n",
    "            \n",
    "            # Run inference\n",
    "            outputs = session.run(None, {input_name: sample_input})\n",
    "            \n",
    "            print(f\"Input shape: {sample_input.shape}\")\n",
    "            print(f\"Output shape: {outputs[0].shape}\")\n",
    "            \n",
    "            # Check if output dimensions match input or are padded\n",
    "            if outputs[0].shape[2:] != sample_input.shape[2:]:\n",
    "                print(\"⚠️ Dimension mismatch!\")\n",
    "                print(f\"Height diff: {outputs[0].shape[2] - sample_input.shape[2]}\")\n",
    "                print(f\"Width diff: {outputs[0].shape[3] - sample_input.shape[3]}\")\n",
    "            \n",
    "            # Check if output dimensions are multiples of 8\n",
    "            for dim in outputs[0].shape[2:]:\n",
    "                if dim % 8 != 0:\n",
    "                    print(f\"⚠️ Output dimension {dim} is not a multiple of 8\")\n",
    "        \n",
    "        print(\"\\nValue statistics for last test case:\")\n",
    "        output = outputs[0]\n",
    "        print(f\"Min value: {output.min()}\")\n",
    "        print(f\"Max value: {output.max()}\")\n",
    "        print(f\"Mean value: {output.mean()}\")\n",
    "        print(f\"Has NaN: {np.isnan(output).any()}\")\n",
    "        print(f\"Has Inf: {np.isinf(output).any()}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error testing model: {str(e)}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    test_onnx_model_with_padding(\"./models/pressure_predict_H2.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc1b27-aeca-4e70-ab29-361bcae144f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asdf asdf\n",
    "\n",
    "# Modified export code that maintains original model structure\n",
    "def export_to_onnx(model_path, output_path):\n",
    "    \"\"\"Helper function to export saved model to ONNX format\"\"\"\n",
    "    import tf2onnx\n",
    "    import onnx\n",
    "    \n",
    "    # Load the saved model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Convert to ONNX\n",
    "    input_signature = [tf.TensorSpec([1, None, None, 3], tf.float32, name=\"input\")]\n",
    "    model_proto, _ = tf2onnx.convert.from_keras(\n",
    "        model, \n",
    "        input_signature=input_signature,\n",
    "        #opset=13,\n",
    "        inputs_as_nchw=['input'],\n",
    "        outputs_as_nchw=['unpad_layer']\n",
    "    )\n",
    "    \n",
    "    # Save the ONNX model\n",
    "    onnx.save(model_proto, output_path)\n",
    "    print(f\"Model exported to {output_path}\")\n",
    "\n",
    "model_path = \"./models/pressure_predict_H.keras\"\n",
    "output_path = \"./models/pressure_predict_H_old3.onnx\"\n",
    "export_to_onnx(model_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e23e6f-1c8a-46aa-9d64-534c28d83b82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asdf asdf\n",
    "import tf2onnx\n",
    "# Helper libraries for transposition of NHWC (model) to NCHW (Houdini)\n",
    "import onnx\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model(\n",
    "    \"./models/pressure_predict_H.keras\",\n",
    "    custom_objects={\n",
    "        \"DynamicPaddingLayer\": DynamicPaddingLayer, \n",
    "        \"UnpadLayer\": UnpadLayer\n",
    "    }\n",
    ")\n",
    "\n",
    "output_path = \"./models/pressure_predict_H_old1.onnx\"\n",
    "\n",
    "# Define batch dim\n",
    "input_shape = (None, 64, 64, 3)  # Add None as batch dimension\n",
    "\n",
    "# Create input signature with batch dimension\n",
    "input_signature = [tf.TensorSpec(shape=input_shape, dtype=tf.float32, name='input')]\n",
    "\n",
    "# Convert the model\n",
    "model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=input_signature, inputs_as_nchw=['input'],  outputs_as_nchw=['conv2d_transpose_5'], opset=13)\n",
    "\n",
    "# Save the model\n",
    "with open(output_path, \"wb\") as f:\n",
    "    f.write(model_proto.SerializeToString())\n",
    "# tf2onnx.utils.save_onnx_model(onnx_model, output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4413f8-8465-49c9-87b2-92708e6bbced",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asdf asdf\n",
    "# Define batch dim\n",
    "input_shape = (None, 64, 64, 3)  # Add None as batch dimension\n",
    "\n",
    "# Create input signature with batch dimension\n",
    "input_signature = [tf.TensorSpec(shape=input_shape, dtype=tf.float32, name='input')]\n",
    "\n",
    "# Convert to ONNX\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(\n",
    "    model,\n",
    "    input_signature=input_signature,\n",
    "    opset=13,\n",
    "    inputs_as_nchw=['input'],\n",
    "    #outputs_as_nchw=['output']  # As you mentioned this was the correct setting\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "input_signature = [tf.TensorSpec((None, 64, 64, 3), tf.float32, name='input')]\n",
    "\n",
    "# Create custom configuration to prevent automatic transpose\n",
    "extra_opset = []\n",
    "inputs_as_nchw = ['input']\n",
    "custom_ops = {}\n",
    "custom_op_handlers = {}\n",
    "custom_rewriter = {}\n",
    "\n",
    "# Set target correctly\n",
    "target = None  # Let tf2onnx use default target\n",
    "# Or specify explicitly if needed:\n",
    "# target = \"onnx\"\n",
    "\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(\n",
    "    model,\n",
    "    input_signature=input_signature,\n",
    "    opset=13,\n",
    "    inputs_as_nchw=inputs_as_nchw,\n",
    "    custom_ops=custom_ops,\n",
    "    custom_op_handlers=custom_op_handlers,\n",
    "    custom_rewriter=custom_rewriter,\n",
    "    target=target,\n",
    "    extra_opset=extra_opset\n",
    ")\n",
    "\n",
    "output_path = \"./models/pressure_predict_H_old2.onnx\"\n",
    "with open(output_path, \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "\n",
    "print(f\"Model successfully converted to ONNX and saved as {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
